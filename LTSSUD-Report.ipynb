{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LTSSUD-Report.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"5b2dcf7c"},"source":["# Báo cáo đồ án môn \"Lập trình song song ứng dụng\"\n","\n","Nhóm 5:\n","1. 1712718 - Huỳnh Thanh Sang - [GitHub](https://github.com/hts7117)\n","2. 1712683 - Phạm Hoàng Phương - [Github](https://github.com/superman19993)\n","3. 1712584 - Nguyễn Công Lý - [GitHub](https://github.com/conglyne222)\n","\n","Link thùng chứa Github của nhóm: [Repo](https://github.com/superman19993/LTSSUD_1712718_1712683_1712584)\n"]},{"cell_type":"markdown","metadata":{"id":"2f93d974"},"source":["## Mô tả ứng dụng\n","  ### Object detection and Segmentation by Mask RCNN\n","  - Input: Ảnh đầu vào có kích thước W x H ![image.png](https://scontent.fsgn5-9.fna.fbcdn.net/v/t1.15752-9/277380635_662833644832542_6356397547685485335_n.jpg?_nc_cat=105&ccb=1-5&_nc_sid=ae9488&_nc_ohc=jB9jbjeLC10AX-Yzd47&_nc_ht=scontent.fsgn5-9.fna&oh=03_AVL57_7pZvCV8dNWX_QjrJck_jP1h1AJ8Y9pYSLfPnc6-Q&oe=626ED38B)\n","  - Output: Các bounding box:[cx, cy, w, h] (tọa độ tâm + kích thước) tại các vị trí nghi ngờ có cá thể ![image.png](https://scontent.fsgn5-13.fna.fbcdn.net/v/t1.15752-9/277262287_1207776213380954_9024006818679567261_n.jpg?_nc_cat=104&ccb=1-5&_nc_sid=ae9488&_nc_ohc=poGvM4_xUf0AX8uv1Ym&_nc_ht=scontent.fsgn5-13.fna&oh=03_AVLbmcpGtehwLCGbdCKkpenj4FN3iOQGcz1-qGGB-HwX9A&oe=626BD5BA)\n","\n","  - Framework của bài toán: ![image.png](https://scontent.fsgn5-5.fna.fbcdn.net/v/t1.15752-9/276021156_548651876683254_6016110322686193894_n.png?_nc_cat=100&ccb=1-5&_nc_sid=ae9488&_nc_ohc=ckXISxUADFYAX_pDEvq&_nc_ht=scontent.fsgn5-5.fna&oh=03_AVJN_vkl_ifJCDKZqRY4bczOy-tb4S8YPSDgP9DNSGF-Mw&oe=626BBCFF)\n","  - Trong đề tài này, nhóm 5 lấy mô hình object detection and segmentation by Mask RCNN đã được huấn luyện từ trước để thực hiện tối ưu về thời gian chạy.\n","  - Mô hình trên được huấn luyện từ tập dữ liệu COCO (200.000 ảnh, 80 lớp, 1.500.000 cá thể).\n","\n","\n","\n","\n","  ### Lý do chọn đề tài: \n","  - Bài toán sử dụng mạng CNN (liên quan đến tác vụ convolution trên ảnh)."]},{"cell_type":"markdown","source":["## Kiến trúc Mask-RCNN\n"],"metadata":{"id":"rU6jhqtIJZ1g"}},{"cell_type":"markdown","source":["![image.png](https://scontent-hkg4-2.xx.fbcdn.net/v/t1.15752-9/278021850_714827902981298_8096012180834245696_n.png?_nc_cat=109&ccb=1-5&_nc_sid=ae9488&_nc_ohc=E4Y24vI4HUoAX8buWt7&tn=ZPvUmtLj3aIjaptG&_nc_ht=scontent-hkg4-2.xx&oh=03_AVKM7EvMqKuoSM00tjZqi0quhHjfyw_eo4gXUFRODZkjnA&oe=6283B58C)\n","- Maximum size ảnh là 800 x 1333\n","- Các chỉ số width và height cần phải chia hết cho 32 vì ở feature map được sinh ra ở layer cuối cùng của FPN có kích thước là w/32, h/32."],"metadata":{"id":"P-CVJWt-Z6O2"}},{"cell_type":"markdown","source":["### Phát sinh ứng viên (Region Proposal)\n","- Đầu tiên các ảnh input đầu vào được đưa qua mạng rút trích đặc trưng bằng 1 trong các cách Feature Pyramid Network( FPN) để rút ra các feature map. Kích thước của feature map nhỏ hơn rất nhiều so với ảnh ban đầu, bù lại số channel tăng lên nên vẫn bảo toàn được thông tin cấu trúc ảnh.\n","- Sau đó sẽ duyệt trên từng ô của feature map một lần duy nhất, tại mỗi ô sẽ sinh ra k anchor box có kích thước cố định. Cách sinh anchor box này đảm bảo mô hình có thể nhận dạng được các cá thể thuộc mọi kích thước và hình dạng khác nhau.\n","- Minh họa anchor box k=9\n","![image.png](https://scontent.xx.fbcdn.net/v/t1.15752-9/277967659_2116324165207464_498970705263918862_n.png?_nc_cat=104&ccb=1-5&_nc_sid=aee45a&_nc_ohc=cWy5fHPVNbQAX8CY7ST&_nc_ad=z-m&_nc_cid=0&_nc_ht=scontent.xx&oh=03_AVJbspaszyA_gIFUTo7K9bOHaBzYPkXn7lLQqAQVchLLWA&oe=628762EA)\n","\n","\n","- Feature map đang xét sau đó được đưa vào RPN( Region Proposal Network) để kiểm tra từng anchor box có chứa vật thể không và tinh chỉnh anchor box đó. Những anchor box có chứa vật thể sẽ được làm bounding box ứng viên"],"metadata":{"id":"_M6MMy_fLDlo"}},{"cell_type":"markdown","source":["### Phân lớp (Classification)\n","- Sau đó các bounding box ứng viên sẽ được đưa qua ROI Align để crop các feature map ở các ứng viên ra.\n","- Phần feature map sau khi thực hiện ROIAlign sẽ được đưa vô một mạng fully-connected gồm 2 nhánh để tìm ra class id tương ứng với bounding box đầu vào và tinh chỉnh lại bounding box đầu vào để tăng độ chính xác. "],"metadata":{"id":"GSjcnMOnV-Jx"}},{"cell_type":"markdown","source":["### Phân đoạn ảnh (Segmentation)\n","- Với bounding box được tinh chỉnh ở phần phân lớp, chúng ta lại crop feature map từ bước rút trích đặc trưng và cho qua ROIAlign. Phần feature map kết quả sẽ được cho qua một 1 mạng Convolution với output có kích thước tổng số class x 28 x 28. Cuối cùng, lấy output thứ class_id (kết quả phân lớp) và resize lại cho kích thước ban đầu của bounding box ta được binary mask cần tìm."],"metadata":{"id":"O7uH8ovLZhph"}},{"cell_type":"markdown","source":["## Mask R-CNN inference stage\n","A quick intro to using the pre-trained model to detect and segment objects."],"metadata":{"id":"4CEo9XLVMoZH"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2QhTrx-XgUA4","executionInfo":{"status":"ok","timestamp":1650155739697,"user_tz":-420,"elapsed":29194,"user":{"displayName":"Phuong Pham","userId":"07728519156790628751"}},"outputId":"2db02546-6877-4eff-92c0-9b49a6b1e484"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["%cd gdrive/MyDrive/LTSS_UD/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-vwJeg-whOw9","executionInfo":{"status":"ok","timestamp":1650155743480,"user_tz":-420,"elapsed":577,"user":{"displayName":"Phuong Pham","userId":"07728519156790628751"}},"outputId":"024c00cf-a1ac-436f-ffb2-ddb5291e8c87"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/LTSS_UD\n"]}]},{"cell_type":"code","source":["%tensorflow_version 1.14.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4sQ2DAJzfAv_","executionInfo":{"status":"ok","timestamp":1650155746753,"user_tz":-420,"elapsed":1025,"user":{"displayName":"Phuong Pham","userId":"07728519156790628751"}},"outputId":"52b4a24a-b999-4dad-a18b-4cd5e5466d08"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["`%tensorflow_version` only switches the major version: 1.x or 2.x.\n","You set: `1.14.0`. This will be interpreted as: `1.x`.\n","\n","\n","TensorFlow 1.x selected.\n"]}]},{"cell_type":"code","source":["!cp saving.py /tensorflow-1.15.2/python3.7/keras/engine"],"metadata":{"id":"xixxCJv-4IBi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python testing.py"],"metadata":{"id":"AEjgZkZ4IdAT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650162083324,"user_tz":-420,"elapsed":20272,"user":{"displayName":"Phuong Pham","userId":"07728519156790628751"}},"outputId":"e146ead4-1bbf-4ef3-b290-09933d28ad22"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using TensorFlow backend.\n","WARNING:tensorflow:From /content/gdrive/MyDrive/LTSS_UD/mrcnn/model.py:37: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /content/gdrive/MyDrive/LTSS_UD/mrcnn/model.py:39: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","2022-04-17 02:21:05.169431: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n","2022-04-17 02:21:05.169623: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555a73ef3800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2022-04-17 02:21:05.169654: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2022-04-17 02:21:05.171237: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2022-04-17 02:21:05.400114: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-17 02:21:05.400857: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555a73ef3100 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2022-04-17 02:21:05.400889: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2022-04-17 02:21:05.401061: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-17 02:21:05.401588: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2022-04-17 02:21:05.401903: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2022-04-17 02:21:05.403342: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2022-04-17 02:21:05.404172: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2022-04-17 02:21:05.404468: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2022-04-17 02:21:05.405847: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2022-04-17 02:21:05.406557: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2022-04-17 02:21:05.409379: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-17 02:21:05.409499: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-17 02:21:05.410088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-17 02:21:05.410580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2022-04-17 02:21:05.410659: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2022-04-17 02:21:05.411912: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-04-17 02:21:05.411938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2022-04-17 02:21:05.411948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2022-04-17 02:21:05.412079: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-17 02:21:05.412643: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-17 02:21:05.413228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","\n","Configurations:\n","BACKBONE                       resnet101\n","BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n","BATCH_SIZE                     1\n","BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n","COMPUTE_BACKBONE_SHAPE         None\n","DETECTION_MAX_INSTANCES        100\n","DETECTION_MIN_CONFIDENCE       0.7\n","DETECTION_NMS_THRESHOLD        0.3\n","FPN_CLASSIF_FC_LAYERS_SIZE     1024\n","GPU_COUNT                      1\n","GRADIENT_CLIP_NORM             5.0\n","IMAGES_PER_GPU                 1\n","IMAGE_CHANNEL_COUNT            3\n","IMAGE_MAX_DIM                  1024\n","IMAGE_META_SIZE                93\n","IMAGE_MIN_DIM                  800\n","IMAGE_MIN_SCALE                0\n","IMAGE_RESIZE_MODE              square\n","IMAGE_SHAPE                    [1024 1024    3]\n","LEARNING_MOMENTUM              0.9\n","LEARNING_RATE                  0.001\n","LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n","MASK_POOL_SIZE                 14\n","MASK_SHAPE                     [28, 28]\n","MAX_GT_INSTANCES               100\n","MEAN_PIXEL                     [123.7 116.8 103.9]\n","MINI_MASK_SHAPE                (56, 56)\n","NAME                           coco\n","NUM_CLASSES                    81\n","POOL_SIZE                      7\n","POST_NMS_ROIS_INFERENCE        1000\n","POST_NMS_ROIS_TRAINING         2000\n","PRE_NMS_LIMIT                  6000\n","ROI_POSITIVE_RATIO             0.33\n","RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n","RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n","RPN_ANCHOR_STRIDE              1\n","RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n","RPN_NMS_THRESHOLD              0.7\n","RPN_TRAIN_ANCHORS_PER_IMAGE    256\n","STEPS_PER_EPOCH                1000\n","TOP_DOWN_PYRAMID_SIZE          256\n","TRAIN_BN                       False\n","TRAIN_ROIS_PER_IMAGE           200\n","USE_MINI_MASK                  True\n","USE_RPN_ROIS                   True\n","VALIDATION_STEPS               200\n","WEIGHT_DECAY                   0.0001\n","\n","\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /content/gdrive/MyDrive/LTSS_UD/mrcnn/model.py:349: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /content/gdrive/MyDrive/LTSS_UD/mrcnn/model.py:407: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/gdrive/MyDrive/LTSS_UD/mrcnn/model.py:431: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n","Instructions for updating:\n","box_ind is deprecated, use box_indices instead\n","WARNING:tensorflow:From /content/gdrive/MyDrive/LTSS_UD/mrcnn/model.py:728: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n","\n","WARNING:tensorflow:From /content/gdrive/MyDrive/LTSS_UD/mrcnn/model.py:730: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n","\n","WARNING:tensorflow:From /content/gdrive/MyDrive/LTSS_UD/mrcnn/model.py:780: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","2022-04-17 02:21:16.448977: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2022-04-17 02:21:16.650984: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","{'rois': array([[335,   0, 620, 384],\n","       [307, 257, 434, 348],\n","       [167, 266, 226, 298],\n","       [220,  57, 274,  98],\n","       [259, 192, 331, 219]], dtype=int32), 'class_ids': array([60, 57,  1,  1,  1], dtype=int32), 'scores': array([0.9948183 , 0.98643667, 0.9126583 , 0.8841086 , 0.8734573 ],\n","      dtype=float32), 'masks': array([[[False, False, False, False, False],\n","        [False, False, False, False, False],\n","        [False, False, False, False, False],\n","        ...,\n","        [False, False, False, False, False],\n","        [False, False, False, False, False],\n","        [False, False, False, False, False]],\n","\n","       [[False, False, False, False, False],\n","        [False, False, False, False, False],\n","        [False, False, False, False, False],\n","        ...,\n","        [False, False, False, False, False],\n","        [False, False, False, False, False],\n","        [False, False, False, False, False]],\n","\n","       [[False, False, False, False, False],\n","        [False, False, False, False, False],\n","        [False, False, False, False, False],\n","        ...,\n","        [False, False, False, False, False],\n","        [False, False, False, False, False],\n","        [False, False, False, False, False]],\n","\n","       ...,\n","\n","       [[False, False, False, False, False],\n","        [False, False, False, False, False],\n","        [False, False, False, False, False],\n","        ...,\n","        [False, False, False, False, False],\n","        [False, False, False, False, False],\n","        [False, False, False, False, False]],\n","\n","       [[False, False, False, False, False],\n","        [False, False, False, False, False],\n","        [False, False, False, False, False],\n","        ...,\n","        [False, False, False, False, False],\n","        [False, False, False, False, False],\n","        [False, False, False, False, False]],\n","\n","       [[False, False, False, False, False],\n","        [False, False, False, False, False],\n","        [False, False, False, False, False],\n","        ...,\n","        [False, False, False, False, False],\n","        [False, False, False, False, False],\n","        [False, False, False, False, False]]])}\n"]}]}]}